{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/gephi_network.png?raw=true\" align=\"right\" width=\"300\">\n",
    "\n",
    "\n",
    "# SC207 - Session 8\n",
    "# Social Network Analysis with Gephi\n",
    "## Reshaping your Data into a Network\n",
    "\n",
    "\n",
    "### Imports\n",
    "\n",
    "Today we will just need...\n",
    "- Pandas to import and reshape our twitter data\n",
    "\n",
    "- <img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/gephi-logo-2010-transparent.png?raw=true\" align=\"left\" width=\"75\">....to visualise and explore our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def flatten_nested_dicts(df):\n",
    "    dicts = df.to_dict(orient='records')\n",
    "    flattened = pd.json_normalize(dicts)\n",
    "    return flattened"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Converting Twitter Data\n",
    "\n",
    "- We're going to make a Retweet network. \n",
    "- In this network every Node will represent a different user, \n",
    "- An edge between user a and user b will represent one user retweeting the other\n",
    "- Edges will be given a `weight` that counts how many unique times user a retweeted user b.\n",
    "- We will make our network `directional` meaning that we will record seperately.\n",
    "  -     how many times `a` is retweeted by -> `b` \n",
    "  -     and how many times `b` -> is retweeted by `a`\n",
    "\n",
    "#### Stage 1\n",
    "We currently have data laid out like this...\n",
    "\n",
    "| author_id | referenced_tweet_id |\n",
    "| --------- | ------------------- |\n",
    "| USER A    | TWEET 1             |\n",
    "| USER B    | TWEET 2             |\n",
    "| USER C    | TWEET 3             |\n",
    "\n",
    "#### Stage 2\n",
    "However we want our data to look like this....\n",
    "\n",
    "| author_id | referenced_tweet_id | referenced_tweet's author |\n",
    "| --------- | ------------------- | ------------------------- |\n",
    "| USER A    | TWEET 1             | USER B                    |\n",
    "| USER B    | TWEET 2             | USER A                    |\n",
    "| USER C    | TWEET 3             | USER C                    |\n",
    "\n",
    "\n",
    "#### Stage 3\n",
    "Or actually more accurately, just like this...\n",
    "\n",
    "| retweeter | author |\n",
    "|-----------|--------|\n",
    "| USER A    | USER B |\n",
    "| USER B    | USER A |\n",
    "| USER C    | USER C |\n",
    "\n",
    "#### Stage 4\n",
    "We create a weight column that represents the number of times the author_id retweeted the referenced_tweet's author.\n",
    "\n",
    "| retweeter | author | weight |\n",
    "|-----------| ---------------------- |--------|\n",
    "| USER A    | USER B                 |1|\n",
    "| USER B    | USER A                 |5|\n",
    "| USER C    | USER C                 |12|\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stage 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = 'QT.json'\n",
    "\n",
    "tweets = pd.read_json(filename)\n",
    "tweets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subset = tweets[['author_id','referenced_tweets']].dropna()\n",
    "subset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first we deal with everything being in lists using .explode!!\n",
    "\n",
    "edge_data = subset.explode('referenced_tweets').copy()\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Next we unpack that series of dictionaries into their own columns\n",
    "edge_data = flatten_nested_dicts(edge_data)\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# and select just three columns, the original author id, the tweet id of the referenced tweet, and the type of the referenced tweet\n",
    "\n",
    "edge_data = edge_data[['author_id','referenced_tweets.id', 'referenced_tweets.type']]\n",
    "edge_data = edge_data[edge_data['referenced_tweets.type'] == 'retweeted']\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So to recap, we have three columns...\n",
    "- source: The id of the user that retweeted somebody.\n",
    "- id: The id of the tweet that they retweeted\n",
    "- type: the way in which the source 'referenced' a tweet. In our case all retweets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stage 2\n",
    "Our hope is that all the referenced tweets are also in our dataset somewhere else, and so have associated user information. We'll create a new dataframe of tweet ids and associated user ids and then use merge to match them up."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here we create a list of all the tweets we collected and associated author id.\n",
    "user_data = tweets[['id','author_id']]\n",
    "user_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edge_data = edge_data.merge(user_data, how='left',left_on='referenced_tweets.id', right_on='id')\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stage 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here we check if we're missing any author info for any reason. If we were we'd just use .dropna() to drop any rows with missing info.\n",
    "edge_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here we will rename the columns to be more descriptive, and drop any columns we don't need.\n",
    "\n",
    "new_cols = {'author_id_x':'retweeter', 'author_id_y':'author'}\n",
    "edge_data = edge_data.rename(columns=new_cols).drop(columns=['referenced_tweets.id','id','referenced_tweets.type'])\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stage 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At the moment we have one row per instance of retweeting between a pair of users. However it may be the case that one user retweeted another a number of times, and so there are duplicate rows. Rather than discard this information, we'll capture this by adding weights to our edges that count how many times the source user retweeted the target user."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# First we give every edge a weight of 1, because each row represents 1 instance of retweeting\n",
    "\n",
    "edge_data['weight'] = 1\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we use groupby to gather together rows that have the same combination of source, target and type, and add the weight values together."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edge_data = edge_data.groupby(['retweeter','author'],as_index=False).sum()\n",
    "edge_data.sort_values('weight',ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now our `edge_data` has one row per pair, and a weight indicating how many times that pair appeared in the data. Finally we just need to relabel the columns so that Gephi understands them.\n",
    "\n",
    "In network analysis when we talk about edges we refer to a `source` and a `target`. If you imagine an edge as an arrow the `source` is where the arrow starts and the `target` is where it points to.\n",
    "\n",
    "In our case the direction matters, just because USER A retweete USER B doesn't mean that they retweeted back. The relationship is not necessarily mutual, like perhaps a friendship where we wouldn't necessarily consider there to be a direction to the connection. Which is the source and which is the target though? Well, either, depending on how you define what the edge represents.\n",
    "\n",
    "We could say the edge means `RETWEETED`, so it would be...\n",
    "\n",
    "```\n",
    "(SOURCE: retweeter) -[RETWEETED]-> (TARGET: author)\n",
    "```\n",
    "\n",
    "But equally we could say the edge means `RETWEETED_BY`, meaning the positions would be reversed.\n",
    "\n",
    "```\n",
    "(SOURCE: author) -[RETWEETED_BY]-> (TARGET: retweeter)\n",
    "```\n",
    "\n",
    "In this case, it doesn't matter what we choose, so long as we remember what the direction of our edge represents. We'll go with `RETWEETED`.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gephi_edge_labels = {'retweeter':'Source','author':'Target'}\n",
    "edge_data = edge_data.rename(columns=gephi_edge_labels)\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edge_data.to_csv('edges_QT.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Nodes\n",
    "- `source_user_id` and `target_user_id` as the node ids.\n",
    "- `source_username` and `target_username` as the node labels\n",
    "- User followers count and statuses count as the node attributes\n",
    "\n",
    "### Edges\n",
    "-  `source_user_id` and `target_user_id` as the two ends of our edges."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Nodes\n",
    "This dataframe will be a list of unique nodes and we will assign some attributes to the nodes that we can use in Gephi later on.\n",
    "First we grab the relevant columns from our original dataset. It may have duplicates as each row represents a tweet, and it may have users that didn't end up in our edge table but we'll deal with that soon."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "node_data = tweets[['user_id','user_name','user_public_metrics']]\n",
    "node_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# First we drop any duplicates because we simply need one row per user\n",
    "node_data = node_data.drop_duplicates('user_id')\n",
    "node_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Next we create a list of all users that are actually in our edge list\n",
    "\n",
    "nodes_in_network = pd.concat([edge_data['Source'], edge_data['Target']], axis=0).drop_duplicates()\n",
    "nodes_in_network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "node_data = node_data[node_data['user_id'].isin(nodes_in_network)]\n",
    "node_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now lets expand out our user metrics\n",
    "\n",
    "node_data = flatten_nested_dicts(node_data)\n",
    "node_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Finally we need to relabel our columns for Gephi\n",
    "\n",
    "gephi_node_labels = {'user_id':'ID','user_name':'Label',\n",
    "                     'user_public_metrics.followers_count':'followers_count',\n",
    "                     'user_public_metrics.following_count':'following_count',\n",
    "                     'user_public_metrics.tweet_count':'tweet_count',\n",
    "                     'user_public_metrics.listed_count':'listed_count'}\n",
    "\n",
    "node_data = node_data.rename(columns=gephi_node_labels)\n",
    "node_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "node_data.to_csv('retweet_node_list.csv',index=False)\n",
    "edge_data.to_csv('retweet_edge_list.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}