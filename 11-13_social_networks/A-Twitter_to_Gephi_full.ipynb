{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/gephi_network.png?raw=true\" align=\"right\" width=\"300\">\n",
    "\n",
    "\n",
    "# SC207 - Session 8\n",
    "# Social Network Analysis with Gephi\n",
    "## Reshaping your Data into a Network\n",
    "\n",
    "\n",
    "### Imports\n",
    "\n",
    "Today we will just need...\n",
    "- Pandas to import and reshape our twitter data\n",
    "\n",
    "- <img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/gephi-logo-2010-transparent.png?raw=true\" align=\"left\" width=\"75\">....to visualise and explore our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Converting Twitter Data\n",
    "\n",
    "- We're going to make a Retweet network. \n",
    "- In this network every Node will represent a different user, \n",
    "- An edge between user a and user b will represent one user retweeting the other\n",
    "- Eges will be given a `weight` that counts how many unique times user a retweeted user b. \n",
    "- We will make our network `directional` meaning that we will record seperately\n",
    "  -     how many times `a` is retweeted by -> `b` \n",
    "  -     and how many times `b` -> is retweeted by `a`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'example_twitter_data.pkl'\n",
    "\n",
    "tweets = pd.read_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Our Unpacking Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_nested_dicts(df):\n",
    "    dicts = df.to_dict(orient='records')\n",
    "    flattened = pd.json_normalize(dicts)\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Nodes\n",
    "- User screen names as the id and Label.\n",
    "- User followers count and statuses count as the node attributes\n",
    "\n",
    "### Edges \n",
    "-  `user.screen_name` and the `retweeted_status.user.screen_name` as the two ends of our edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First let's grab just the portion of data we need\n",
    "\n",
    "tweet_network_data = tweets[['id','user', 'retweeted_status']]\n",
    "tweet_network_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# and then we unpack...may take a few seconds...\n",
    "\n",
    "tweet_network_data = flatten_nested_dicts(tweet_network_data)\n",
    "tweet_network_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we create our edge list, which represents who retweets who.\n",
    "\n",
    "`user.screen_name` is the user that initated the retweet, whilst `retweeted_status.user.screen_name` is the original author of the tweet being retweeted.\n",
    "\n",
    "We can think of this edge like so...\n",
    "\n",
    "\n",
    "(`user.screen_name`) -[RETWEETED]-> (`retweeted_status.user.screen_name`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "edges = tweet_network_data[['user.screen_name', 'retweeted_status.user.screen_name']]\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some of these tweets will not be Retweets, and so will have a `NaN` value in the `retweeted_status.user.screen_name` column. We can check with `edges.info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "edges.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's drop any rows that don't have a value under `retweeted_status.user.screen_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we could be specific with a filter but we can also use .dropna as a shortcut\n",
    "\n",
    "edges = edges.dropna()\n",
    "edges.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Rename the columns so that it is clear which is source and which is target\n",
    "edges = edges.rename(columns={'user.screen_name': 'source', 'retweeted_status.user.screen_name' :'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We also said we were going to make sure we had just one edge between each pair, but assign the edge a 'weight' score that indicated how many times that retweeting had happened. We can do this quickly using Pandas Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# first we give every edge a weight of 1\n",
    "\n",
    "edges['weight'] = 1\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Then we group by both the source and the target columns and sum together the weights\n",
    "\n",
    "edges.groupby(['source','target'], as_index=False).sum().sort_values('weight',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Looks good, lets finalise that by overwriting our edges variable- no need to sort it\n",
    "edges = edges.groupby(['source','target'], as_index=False).sum().reset_index(drop=True)\n",
    "edges['edge_type'] = 'retweeted'\n",
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally - Often you get a lot of 'noise' in the sense that you may have many instances of a user existing in the dataset just because they retweeted once. This could be useful in some cases, but often the noise hides the underlying structures of relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Nodes\n",
    "This dataframe will be a list of unique nodes and we will assign some attributes to the nodes that we can use in Gephi later on.\n",
    "\n",
    "First we take both the source and target columns, and append one to the other to make a long list of every user in the edges.\n",
    "\n",
    "We drop duplicates as users may be mentioned multiple times, and then convert to a dataframe using `.to_frame` rather than a single column, specifying the dataframe's one column name to be `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# first we take our source and target column, and stack them on top of each other\n",
    "# This will create a list of every user in our edge list\n",
    "\n",
    "node_names = edges['source'].append(edges['target'])\n",
    "node_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We have duplicates because our edge list relies on duplicating names to properly represent\n",
    "# how one user may have formed edges between multiple other nodes.\n",
    "\n",
    "# A node list should be a list of unique nodes and their attributes, \n",
    "# so we will drop the duplicates and turn the Series into a DataFrame\n",
    "unique_nodes = node_names.drop_duplicates().to_frame(name='id').reset_index(drop=True)\n",
    "\n",
    "unique_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Gephi will use the `id` column to match nodes in the nodes list to the nodes mentioned in the edge list. Finally we provide a `Label` column, which is the same as the `id` column but Gephi likes to have a label column which is what is displayed if node labels are on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unique_nodes['Label'] = unique_nodes['id']\n",
    "unique_nodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We want to ensure each user node has its `user.statuses_count` and `user.followers_count` associated. We will need to get these from our original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "attribute_columns = ['user.screen_name','user.followers_count','user.statuses_count']\n",
    "user_data = tweet_network_data[attribute_columns]\n",
    "user_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Currently user_data is essentially a list of tweets showing just the username, and then the status count and follower count of the user at the point they tweeted. This means that a user may occur more than once in the list, with different values. \n",
    "\n",
    "The solution is to ask Pandas to find all the tweets in the dataset for each user, and then choose the highest values it can find in those tweets for each user. We do this with `.groupby` and `.max` to aggregate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_data = user_data.groupby('user.screen_name').max().reset_index()\n",
    "user_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For our list of nodes, we now want to find the corresponding data in our `user_data` variable, for each user and include it in our `unique_nodes` list.\n",
    "\n",
    "We can do this with a \"left `.merge`\" which matches the two dataframes on a specified column and then copies the data from the \"right\" dataframe to the corresponding rows in the \"left\" dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# nodes is on the left, user_data is on the right\n",
    "\n",
    "nodes = unique_nodes.merge(user_data, left_on='id', right_on='user.screen_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# no need for the extra user.screen_name column\n",
    "nodes = nodes.drop(columns=['user.screen_name'])\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nodes.to_csv('retweet_node_list.csv',index=False)\n",
    "edges.to_csv('retweet_edge_list.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we go to...\n",
    "\n",
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/gephi-logo-2010-transparent.png?raw=true\" align=\"left\" width=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Some Notes\n",
    "#### Filter sets\n",
    "\n",
    "To examine individual communities\n",
    "\n",
    "- Giant component\n",
    "    - Inter Edges (modularity Class)\n",
    "        - Degree range 2\n",
    "\n",
    "To examine the overall structure\n",
    "- Giant component\n",
    "    - Degree range 2\n",
    "\n",
    "\n",
    "#### Measures\n",
    "- Weighted in-degree to show influence\n",
    "- Pagerank centrality to show those who may have the ear of an influencer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}