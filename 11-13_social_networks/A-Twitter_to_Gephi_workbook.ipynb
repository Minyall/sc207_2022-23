{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/gephi_network.png?raw=true\" align=\"right\" width=\"300\">\n",
    "\n",
    "\n",
    "# SC207 - Session 8\n",
    "# Social Network Analysis with Gephi\n",
    "## Reshaping your Data into a Network\n",
    "\n",
    "\n",
    "### Imports\n",
    "\n",
    "Today we will just need...\n",
    "- Pandas to import and reshape our twitter data\n",
    "\n",
    "- <img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/gephi-logo-2010-transparent.png?raw=true\" align=\"left\" width=\"75\">....to visualise and explore our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We'll need pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# A function we used to flatten out nested data in our dataset\n",
    "def flatten_nested_dicts(df):\n",
    "    dicts = df.to_dict(orient='records')\n",
    "    flattened = pd.json_normalize(dicts)\n",
    "    return flattened"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Converting Twitter Data\n",
    "\n",
    "- We're going to make a Retweet network. \n",
    "- In this network every Node will represent a different user, \n",
    "- An edge between user a and user b will represent one user retweeting the other\n",
    "- Edges will be given a `weight` that counts how many unique times user a retweeted user b.\n",
    "- We will make our network `directional` meaning that we will record seperately.\n",
    "  -     how many times `a` is retweeted by -> `b` \n",
    "  -     and how many times `b` -> is retweeted by `a`\n",
    "\n",
    "#### Stage 1\n",
    "We currently have data laid out like this...\n",
    "\n",
    "| author_id | referenced_tweet_id |\n",
    "| --------- | ------------------- |\n",
    "| USER A    | TWEET 1             |\n",
    "| USER B    | TWEET 2             |\n",
    "| USER C    | TWEET 3             |\n",
    "\n",
    "#### Stage 2\n",
    "However we want our data to look like this....\n",
    "\n",
    "| author_id | referenced_tweet_id | referenced_tweet's author |\n",
    "| --------- | ------------------- | ------------------------- |\n",
    "| USER A    | TWEET 1             | USER B                    |\n",
    "| USER B    | TWEET 2             | USER A                    |\n",
    "| USER C    | TWEET 3             | USER C                    |\n",
    "\n",
    "\n",
    "#### Stage 3\n",
    "Or actually more accurately, just like this...\n",
    "\n",
    "| retweeter | author |\n",
    "|-----------|--------|\n",
    "| USER A    | USER B |\n",
    "| USER B    | USER A |\n",
    "| USER C    | USER C |\n",
    "\n",
    "#### Stage 4\n",
    "We create a weight column that represents the number of times the author_id retweeted the referenced_tweet's author.\n",
    "\n",
    "| retweeter | author | weight |\n",
    "|-----------| ---------------------- |--------|\n",
    "| USER A    | USER B                 |1|\n",
    "| USER B    | USER A                 |5|\n",
    "| USER C    | USER C                 |12|\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stage 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "filename = 'trhr.json'\n",
    "\n",
    "tweets =\n",
    "tweets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We grab all the rows that have data in the referenced_tweets column\n",
    "subset =\n",
    "subset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first we deal with everything being in lists using .explode!!\n",
    "\n",
    "edge_data =\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Next we unpack that series of dictionaries into their own columns\n",
    "edge_data = flatten_nested_dicts(edge_data)\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# and select just three columns, the original author id, the tweet id of the referenced tweet, and the type of the referenced tweet\n",
    "# We also will select only those rows where the referenced tweet type is a retweet, but you could do this with other types of referenced tweet.\n",
    "edge_data =\n",
    "edge_data =\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So to recap, we have three columns...\n",
    "- source: The id of the user that retweeted somebody.\n",
    "- id: The id of the tweet that they retweeted\n",
    "- type: the way in which the source 'referenced' a tweet. In our case all retweets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stage 2\n",
    "Our hope is that all the referenced tweets are also in our dataset somewhere else, and so have associated user information. We'll create a new dataframe of tweet ids and associated user ids and then use merge to match them up."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here we create a list of all the tweets we collected and associated author id.\n",
    "user_data =\n",
    "user_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here we merge the edge data with the user data, matching the id of the referenced tweet, with the ids in our dataset overall so we can have user info\n",
    "# for both sides of the retweeting interaction, the author and the retweeter.\n",
    "edge_data =\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stage 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here we check if we're missing any author info for any reason. If we were we'd just use .dropna() to drop any rows with missing info.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here we will rename the columns to be more descriptive, and drop any columns we don't need.\n",
    "\n",
    "new_cols =\n",
    "edge_data =\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stage 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At the moment we have one row per instance of retweeting between a pair of users. However it may be the case that one user retweeted another a number of times, and so there are duplicate rows. Rather than discard this information, we'll capture this by adding weights to our edges that count how many times the source user retweeted the target user."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# First we give every edge a weight of 1, because each row represents 1 instance of retweeting\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we use groupby to gather together rows that have the same combination of source, target and type, and add the weight values together."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edge_data =\n",
    "edge_data.sort_values('weight',ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now our `edge_data` has one row per pair, and a weight indicating how many times that pair appeared in the data. Finally we just need to relabel the columns so that Gephi understands them.\n",
    "\n",
    "In network analysis when we talk about edges we refer to a `source` and a `target`. If you imagine an edge as an arrow the `source` is where the arrow starts and the `target` is where it points to.\n",
    "\n",
    "In our case the direction matters, just because USER A retweete USER B doesn't mean that they retweeted back. The relationship is not necessarily mutual, like perhaps a friendship where we wouldn't necessarily consider there to be a direction to the connection. Which is the source and which is the target though? Well, either, depending on how you define what the edge represents.\n",
    "\n",
    "We could say the edge means `RETWEETED`, so it would be...\n",
    "\n",
    "```\n",
    "(SOURCE: retweeter) -[RETWEETED]-> (TARGET: author)\n",
    "```\n",
    "\n",
    "But equally we could say the edge means `RETWEETED_BY`, meaning the positions would be reversed.\n",
    "\n",
    "```\n",
    "(SOURCE: author) -[RETWEETED_BY]-> (TARGET: retweeter)\n",
    "```\n",
    "\n",
    "In this case, it doesn't matter what we choose, so long as we remember what the direction of our edge represents. We'll go with `RETWEETED`.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gephi_edge_labels =\n",
    "edge_data =\n",
    "edge_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Nodes\n",
    "This dataframe will be a list of unique nodes and we will assign some attributes to the nodes that we can use in Gephi later on.\n",
    "First we grab the relevant columns from our original dataset. It may have duplicates as each row represents a tweet, and it may have users that didn't end up in our edge table but we'll deal with that soon."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's check to see what kinds of data are available for us\n",
    "tweets.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We'll create a subset of the user id number, which we'll need to match with our edge data, the username to label the nodes, and then the public metrics for some additional info about the user.\n",
    "node_data =\n",
    "node_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# First we drop any duplicates because we simply need one row per user\n",
    "node_data =\n",
    "node_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Next we create a list of all users that are actually in our edge list by concatenating the two edge columns together into one list, and then dropping any duplicates.\n",
    "\n",
    "nodes_in_network =\n",
    "nodes_in_network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now we'll use that list of the nodes in the network to filter our node_data information so that it only contains data on nodes that we have edges for.\n",
    "node_data =\n",
    "node_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now lets expand out our user metrics by flattening the dataframe\n",
    "\n",
    "node_data =\n",
    "node_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Finally we need to relabel our columns for Gephi\n",
    "\n",
    "gephi_node_labels =\n",
    "\n",
    "node_data =\n",
    "node_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# All that is left is to save the node data and edge data to two csv files ready for Gephi.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Woah that was a lot!\n",
    "Yes it was, but we show you the steps so you understand the process. However it can be simplified down into a few functions to make your life easier."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def flatten_nested_dicts(df):\n",
    "    dicts = df.to_dict(orient='records')\n",
    "    flattened = pd.json_normalize(dicts)\n",
    "    return flattened\n",
    "\n",
    "def create_rt_edge_list(tweet_df):\n",
    "    \"\"\"\"Creates an edge list where the Source is the retweeter, and the Target is the original tweet author. (Source)-[RETWEETED]-(Target)\"\"\"\n",
    "\n",
    "    subset = tweet_df[['author_id','referenced_tweets']].dropna()\n",
    "    edge_data = subset.explode('referenced_tweets').copy()\n",
    "    edge_data = flatten_nested_dicts(edge_data)\n",
    "    edge_data = edge_data[['author_id','referenced_tweets.id', 'referenced_tweets.type']]\n",
    "    edge_data = edge_data[edge_data['referenced_tweets.type'] == 'retweeted']\n",
    "\n",
    "    user_data = tweet_df[['id','author_id']]\n",
    "    edge_data = edge_data.merge(user_data, how='left',left_on='referenced_tweets.id', right_on='id')\n",
    "    edge_data = edge_data.drop(columns=['referenced_tweets.id','id','referenced_tweets.type'])\n",
    "\n",
    "    edge_data['weight'] = 1\n",
    "    edge_data = edge_data.groupby(['author_id_x','author_id_y'], as_index=False).sum()\n",
    "    edge_data = edge_data.rename(columns= {'author_id_x':'Source','author_id_y':'Target'})\n",
    "    return edge_data\n",
    "\n",
    "def create_node_list(tweet_df, edges):\n",
    "    \"\"\"\"Creates node list. Requires you pass in both the original tweets dataframe, and your newly created edge list\"\"\"\n",
    "\n",
    "    node_data = tweet_df[['user_id','user_username','user_public_metrics']].drop_duplicates('user_id')\n",
    "    nodes_in_network = pd.concat([edges['Source'],edges['Target']], axis=0).drop_duplicates()\n",
    "\n",
    "    node_data = node_data[node_data['user_id'].isin(nodes_in_network)].copy()\n",
    "    node_data = flatten_nested_dicts(node_data)\n",
    "    gephi_node_labels = {'user_id':'ID','user_username':'Label',\n",
    "                         'user_public_metrics.followers_count':'followers_count',\n",
    "                         'user_public_metrics.following_count':'following_count',\n",
    "                         'user_public_metrics.tweet_count':'tweet_count',\n",
    "                         'user_public_metrics.listed_count':'listed_count'}\n",
    "    node_data = node_data.rename(columns=gephi_node_labels)\n",
    "    return node_data\n",
    "\n",
    "def save_to_disk(edge_list, node_list):\n",
    "    \"\"\"\"Saves node and edge lists to disk in Gephi friendly format\"\"\"\n",
    "    edge_list.to_csv('my_edge_list.csv', index=False)\n",
    "    node_list.to_csv('my_node_list.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}