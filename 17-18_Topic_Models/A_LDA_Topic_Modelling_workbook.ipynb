{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install gensim pyLDAvis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SC207 Text Mining\n",
    "## LDA Topic Modelling\n",
    "### Discovering the latent topics that exist across a corpus\n",
    "\n",
    "More advanced forms of text analysis require that text documents are converted into numerical values or features. In this  section we will examine:\n",
    "\n",
    "* different methods for representing a collection of texts as numbers\n",
    "* the decisions we need to make when generating a particular representation as well as the kinds of insights each numerical representation can give us.\n",
    "\n",
    "## Tools\n",
    "- [Gensim](https://radimrehurek.com/gensim/): A library designed for all manner of text processing. Whilst some of its features exist in SciKit Learn, Gensim provides a more comprehensive range of text analysis models.\n",
    "\n",
    "\n",
    "\n",
    "In this notebook we'll be using a particular type of unsupervised learning called *Topic Modelling*. Topic modelling looks particularly at the words and phrases used in texts and works out, based on how often words appear in different texts, what themes there might be across a collection of documents. Crucially, LDA topic modelling recognises that different documents may express a range of different topics. This can be useful for a range of different research questions that might ask for different groups may deploy or even connect different discourses together.\n",
    "\n",
    "Some limitations to keep in mind...\n",
    "- Topic modelling doesn't consider the ordering of words, just the existence or absence of words\n",
    "- Topic modelling doesn't understand the meaning of words, just the existence or absence of words.\n",
    "- Topic modelling doesn't implicitly know how many topics are in a collection of texts, you have to tell it, and it may be worth varying this number depending on your research question.\n",
    "- Topic modelling can produce junk topics.\n",
    "- There is no objective way to determine if your topic modelling is 'good'. Whilst we have some assessment measures, it relies on a lot of qualitative assessment and knowledge of the documents themselves."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import pyLDAvis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('sample_news_large_with_tokens.csv')\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gensim works a little differently to SciKit learn but it is relatively easy to get up and running...."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Gensim relies on custom built dictionaries and a special object that\n",
    "# they refer to as a corpus but is quite different from how we understand a corpus\n",
    "\n",
    "# The dictionary object expects to recieve a list of documents, and that each document is itself a list of tokens.\n",
    "tokenised_docs =\n",
    "tokenised_docs[0:2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The dictionary creates a reference between words and a reference number\n",
    "gs_dict =\n",
    "\n",
    "# The dictionary's filter extremes method works like our min_df and max_df arguments from our sklearn vectorisers.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we use the dictionary to create a gensim corpus, which is essentially a\n",
    "# list where each entry contains a list of word reference numbers and their frequency in that document.\n",
    "\n",
    "gs_corpus =\n",
    "gs_corpus[:1] # see the first document"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We create our topic model object by passing it this corpus, the dictionary and setting the number of topics.\n",
    "\n",
    "n_topics = 3\n",
    "\n",
    "gs_lda ="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Once it has run we can examine the model...\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Two key things to understand...\n",
    "1. Every document has a score indicating how much it expresses *each* topic. A document could be highly associated with more than one topic.\n",
    "2. Each *word* in the corpus has a score indicating how strongly it is associated with *each* topic.\n",
    "\n",
    "We can see these scores like so..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx = 12\n",
    "df.loc[idx,'title']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Document to topic matrix...\n",
    "doc_topic_matrix =\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# term to topic matrix - note we have one row per topic, and then one column per word in the dictionary\n",
    "term_topic =\n",
    "term_topic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualising your topics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " #### Interpreting LDAvis\n",
    "Run the cell below to save the visual, then go and open it outside of Jupyter. It should open in your web browser.\n",
    "\n",
    "On the left of the screen is the seperate topics.\n",
    "- They are positioned closer, or further from each other, depending on how much the topics overlap. For example we can see that some topics overlap a lot, whilst others are similar, but do not necessarily overlap, indicating there is some distinction between them.\n",
    "- The size of the bubbles indicates how significant those topics are within the overall corpus.\n",
    "- The numbers refer to the topic number but the numbers begin at 1, rather than 0 (helpfully).\n",
    "\n",
    "On the right is the term information for the topics.\n",
    "- If no topic is selected it gives the overall top terms for the corpus\n",
    "- If a topic is selected it shows you the top terms for that topic, including an estimate of how frequent that term is in that topic (red) compared to its overall frequency (blue).\n",
    "- Adjusting the slider at the top right allows you to tweak the measures to show terms more relevant to the topic itself.\n",
    "- Slide all the way to the left to see terms that are highly specific to the topic but to the point that they might be too niche to be meaningful.\n",
    "- Slide all the way to the right for terms that are broader but may be too generic as to not really distinguish the topics.\n",
    "- A good rule of thumb is to set the slider around 0.6 for a balanced output."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyLDAvis.gensim_models import prepare\n",
    "vis =\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How many topics?\n",
    "Yet again the question is, what is the right value for the number of topics? Like before we will run the model multiple times, and score the model to determine which values may be most appropriate.\n",
    "\n",
    "To score the models we can use Gensim's `u_mass` coherence score. This approach looks at how often words co-occur in documents. Topics with high co-occurence words are considered to be more coherent."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#The top topics method lists the best topics in the model based on each topic's coherence\n",
    "# The method outputsa list of topic tuples, the first item in the tuple is a list of topic words and their topic scores, the second is the coherence of that topic.\n",
    "top_topics =\n",
    "top_topics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coherence_scores =\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "average_coherence_score =\n",
    "average_coherence_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k_range = range(1,10)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    model = gensim.models.LdaMulticore(num_topics=k,\n",
    "                                        corpus=gs_corpus,\n",
    "                                        id2word=gs_dict,)\n",
    "    coherence_scores = [item[1] for item in model.top_topics(corpus=gs_corpus)]\n",
    "    avg = sum(coherence_scores) / k\n",
    "\n",
    "    scores.append(avg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(8.2,5.8)})\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examine our top models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_topics = 8\n",
    "\n",
    "chosen_model ="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print topics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vis = prepare(topic_model=chosen_model,\n",
    "                       corpus=gs_corpus,\n",
    "                       dictionary=gs_dict)\n",
    "\n",
    "pyLDAvis.save_html(vis, 'ldavis.html')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Topic assignments\n",
    "\n",
    "doc_topic_matrix = chosen_model.get_document_topics(gs_corpus)\n",
    "assignments = []\n",
    "for i in range(len(df)):\n",
    "    doc_assignments = doc_topic_matrix[i]\n",
    "    high_score_topic, high_score = max(doc_assignments, key= lambda x: x[1])\n",
    "    assignments.append(high_score_topic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assignments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dat = {'topic':assignments,\n",
    "       'query':df['query'].tolist()}\n",
    "\n",
    "hm_data = pd.DataFrame(dat)\n",
    "hm_data['count'] = 1\n",
    "counts = hm_data.groupby(['topic','query'], as_index=True).count().unstack()\n",
    "sns.heatmap(counts, annot=True, linewidths=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "Whilst LDA topic modelling is well established, it often struggles to produce stunningly coherent topics. Particularly when there is significant overlap in those topics. In part this is due to its reliance on word frequency rather than more nuanced approaches. In the next session we'll look at the cutting edge of topic modelling that utilises pre-trained models and adjusted TFIDF scoring for more coherent results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}