{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SC207 - Session 7\n",
    "# APIs - Exploring and Summarising Twitter Data\n",
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/tweepy.jpg?raw=true\" align=\"right\" width=\"300\">\n",
    "\n",
    "\n",
    "What kinds of exploratory analysis can we run on social media data? This session covers various examples of the kinds of insights that can be gathered through the analysis of social media data, and how to present those results.\n",
    "\n",
    "[Tweepy Documentation](http://docs.tweepy.org/en/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'example_twitter_data.pkl'\n",
    "\n",
    "tweets = pd.read_pickle(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Summarising your Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1 How many Tweets did I get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Tweet ids are unique so we can count the number of unique Tweets using nunique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2 When are they from?\n",
    "Twitter can be a very active place, meaning that whilst it may sound like you have a lot of data it may only represent the last 3 minutes. To better understand our dataset we can use the `created_at` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Currently these are just strings, so Pandas doesn't know how to interpret them. If we convert them to a special type called `datetime` Pandas will be able to better handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets['created_at'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets['created_at'] # describe the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.3 How often is it being Tweeted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Whilst our time info is to the second, it is more intuitive to see larger trends by the minute or hour. Grouping by time needs a special object called a `Grouper`.\n",
    "\n",
    "First we create a grouper. We provide it two arguments\n",
    "- The `key` which is the column you want to group by\n",
    "- The `freq` which specifies the time period you want to group by for example 'd' for day, or 'h' for hour, or 'min' for minute.\n",
    "- You can see all the options for freq [here in the Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "time_grouper = \n",
    "count_per_hour = \n",
    "count_per_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make a relplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.4 What types of activity are we seeing?\n",
    "Is this all uniquely written material, or is this a lot of people engaging with the content of others?\n",
    "\n",
    "On Twitter there are retweets. Retweets are where you reproduce and recirculate someone's tweet directly. Though not a hard rule, retweets tend to indicate agreement and can inflate the amount of attention a topic gets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We don't have a column for whether or not a collected tweet is a retweet, but we can make one.\n",
    "# If we check the dataframe info we can see that 'retweeted_status' is a smaller number than our total number of tweets.\n",
    "# if a tweet has data in 'retweeted_status' it is itself a retweet. If not then it's an original tweet.\n",
    "\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We can ask what rows are empty at a particular column using .isna() \n",
    "# We then invert that result (True becomes False and False becomes True) by using tilde ~\n",
    "\n",
    "is_retweet = \n",
    "is_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets['is_retweet_status'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweet_type_data = \n",
    "tweet_type_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "time_grouper = \n",
    "tweet_type_data_to_plot = \n",
    "tweet_type_data_to_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a relplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Unpacking our Data further\n",
    "To better understand the trend we're examining we can do some qualitative and quantitative work but to do this we need to know how to delve deeper into the data to unearth specific information. It would also be helpful to unpack any tweets that are nested in the data as retweets, and add them to our dataset at this point so we have full access to any retweets that were particularly popular.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1 Unpacking Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rt_filter = \n",
    "retweet_df = \n",
    "\n",
    "tweets = \n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We could even turn this into a function...\n",
    "\n",
    "def extract_original_tweets(df):\n",
    "    rt_filter = ~df.retweeted_status.isna()\n",
    "    retweet_df = pd.DataFrame( df[rt_filter]['retweeted_status'].tolist() )\n",
    "\n",
    "    df = df.append(retweet_df).drop_duplicates('id').reset_index(drop=True)\n",
    "    \n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 Unpacking Nested Data\n",
    "To examine the most popular tweets, see what kinds of hashtags are being shared most widely, and see what users are being drawn into the discussion we need to unpack this from the nested data.\n",
    "\n",
    "As a lot of our data is retweets, it may be better to drop these and retain only original tweets to examine the kinds of activity being produced by people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "original_filter = \n",
    "original_tweets = \n",
    "original_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Examining the first rows' 'user' column shows us the complex dictionary object containing all the user info.\n",
    "original_tweets.loc[0,'user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Similarly for entities\n",
    "original_tweets.loc[0,'entities']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We need to use a couple of functions to unpack our nested columns.\n",
    "- `.to_dict(orient='records')` translates a dataframe into a list of dictionaries, each containing their own nested dictionaries\n",
    "- `pd.json_normalize` can create a Dataframe from a list of dictionaries, and flattens out nested dictionaries into their own columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create flatten_nested_dicts function\n",
    "\n",
    "original_tweets = flatten_nested_dicts(original_tweets)\n",
    "original_tweets.info(verbose=True,show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We won't need all of this, let's just grab a subset of columns\n",
    "keep_columns = ['id','full_text','favorite_count','retweet_count',\n",
    "                'user.screen_name', 'entities.hashtags','entities.user_mentions']\n",
    "\n",
    "original_tweets = original_tweets[keep_columns]\n",
    "original_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1 What is the most popular content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tweet_url(screen_name, tweet_id):\n",
    "    return f\"https://twitter.com/{screen_name}/status/{tweet_id}\"\n",
    "\n",
    "def print_top_tweets(data, sort_by):\n",
    "    top_favs = data.sort_values(by=sort_by, ascending=False).head(5)\n",
    "\n",
    "    for index_number, row in top_favs.iterrows():\n",
    "\n",
    "        print('*'*10)\n",
    "        print(\"INDEX:\", index_number)\n",
    "        print(\"USER:\", row['user.screen_name'])\n",
    "        print(\"FAV:\", row['favorite_count'])\n",
    "        print(\"RT:\", row['retweet_count'])\n",
    "        print(row['full_text'])\n",
    "        print(tweet_url(screen_name=row['user.screen_name'], tweet_id=row['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_top_tweets(original_tweets, 'favorite_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_top_tweets(original_tweets, 'retweet_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 Most Popular #Hashtags\n",
    "Examining the hashtags of your data can give you a sense of the discourses around a particular topic, and inform you of connectivity to other issues. The first step is to get the hashtags out of their nested data structure.\n",
    "\n",
    "For each entry in `entities.hashtags` we see a list, which if it is not empty, contains a set of dictionaries, and one value in each dictionary, the `text` value, is what we actually want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hashtag_data = original_tweets[['id','entities.hashtags']].copy()\n",
    "hashtag_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# exploding the dataset puts each item of the nested list into its own row.\n",
    "# This means some Tweets will have multiple rows if they have multiple hashtags.\n",
    "\n",
    "exp_hashtag_data =  # dropna in case any are empty\n",
    "exp_hashtag_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Again we have nested dicts so we can use our function from earlier\n",
    "flat_hashtags = \n",
    "flat_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We can quickly check top hashtags like so...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# or plot them...\n",
    "plot_tag_data = \n",
    "plot_tag_data = \n",
    "plot_tag_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(8, 6)}) # For some reason seaborn doesn't accept height on a bar graph?\n",
    "\n",
    "# barplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In general Twitter activity is very skewed. Very few tweets get any attention, and those that do tend to then dominate the discourse. If we examine the top 50 most favourited tweets we can see that a few tweets get way ahead of the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.3 Most Mentioned Users\n",
    "Similarly we can see what users are most mentioned. Often when big issues hit Twitter, particular key individuals get drawn in as people use their handles to draw their attention to it. Significant amounts of mentioning may also indicate centrality of that user in the wider debate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The steps are the same as above... let's speedrun it!\n",
    "\n",
    "mention_data = original_tweets[['id','entities.user_mentions']].copy()\n",
    "mention_data = mention_data\n",
    "mention_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_mention_data = mention_data.explode('entities.user_mentions').dropna()\n",
    "exp_mention_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Again we have nested dicts so we can use our function from earlier\n",
    "flat_mentions = flatten_nested_dicts(exp_mention_data)\n",
    "flat_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "flat_mentions['entities.user_mentions.screen_name'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# or plot them...\n",
    "plot_user_data = flat_mentions['entities.user_mentions.screen_name'].value_counts().head(20).reset_index()\n",
    "plot_user_data = plot_user_data.rename(columns={'entities.user_mentions.screen_name':'freq', 'index':'name'})\n",
    "plot_user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(8, 6)}) # For some reason seaborn doesn't accept height on a bar graph?\n",
    "sns.barplot(x='freq', y='name', data=plot_user_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}